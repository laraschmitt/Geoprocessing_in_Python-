# Seminar Geoprocessing in Python
### Institute of Geography, HU Berlin, Summer Term 2019

This repository includes my assignments from the introductory course in **Geprocessing in Python** from the Institute of Geography at Humboldt University Berlin.

* ### Lab 1: Basic Python Scripting
     * OS Module: provides a way of using operating system dependent functionality
     * RE Module: Regular Expressions
     * pattern matching
     * for-loop

* ### Lab 2: Introduction to Pandas Dataframe 
     * Pandas Dataframe 
     * filter Dataframe
     * Groupby function
     * GeodataFrame
     * calculating statistics (of pandas Dataframe)

* ### Lab 3: Introduction to GDAL and Numpy
     * function to calculate coordinates of the extent of an image
     * Numpy 3D-array 
     * calculating statistics (of numpy array)
 
* ### Lab 4: Functions for remote sensing image processing
     * function to mask clouds
     * function to calculate a mean composite
     * function to calculate max NDVI composite
     * export numpy array to raster geotif using rasterio module
     
* ### Lab 5: Matplotlib module
    * calculate change magnitude with numpy.diff
    * plot change map with matplotlib module
    * plot histogram 
    
* ### Lab 6: Manipulating shapefiles
    * manipulate shapefile
    * summary statistics in pandas Dataframe
    
* ### Lab 7: Creating summary statistics of a shapefile
    * OGR Module 
    * fill pandas Dataframe with calculated statistics
    * export Dataframe to csv

* ### Lab 8: Reprojecting shapefile layers
    * function to reproject shapefile layers
    * CoordinateTransformation function 
    * function to clip a GeoTiff whith a shapefile 
 
* ### Final assignment: Clasification model with skicit-learn
    * function to transform array position into x, y - coordinates
    * function to create mean from array
    * function to export array to geotiff
    * reproject Landsat file to a different coordinate system 
    * stratified random sample within certain extent
    * join image tiles 
    * generate training dataset
    * standardize training data
    * grid search and cross validation
    * train classification model 
